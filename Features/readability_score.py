# -*- coding: utf-8 -*-
"""Readability Score.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_eUPjZQwY_u2n8ODffVbQbAMrLjbO98e
"""

import pandas as pd
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from collections import defaultdict, Counter
import numpy as np
import re
import string
import nltk
import math

nltk.download('punkt')
nltk.download('stopwords')

df = pd.read_csv('/content/Hc3Finalfeatures.csv')

df = df[['text', 'label']]

# Function to count syllables
def count_syllables(word):
    return max(1, len(re.findall(r'[aeiou]', word, re.I)))

# Function to calculate Flesch-Kincaid Grade Level
def flesch_kincaid_grade(text):
    words = word_tokenize(text)
    sentences = sent_tokenize(text)
    num_words = len(words)
    num_sentences = len(sentences)
    num_syllables = sum(count_syllables(word) for word in words)

    if num_sentences == 0 or num_words == 0:
        return 0

    return 0.39 * (num_words / num_sentences) + 11.8 * (num_syllables / num_words) - 15.59

# Function to calculate Gunning Fog Index
def gunning_fog(text):
    words = word_tokenize(text)
    sentences = sent_tokenize(text)
    num_words = len(words)
    num_sentences = len(sentences)
    complex_words = len([word for word in words if count_syllables(word) > 2])

    if num_sentences == 0 or num_words == 0:
        return 0

    return 0.4 * ((num_words / num_sentences) + 100 * (complex_words / num_words))

# Function to preprocess text
def preprocess_text(text):
    # Join list of sentences into a single string if necessary
    if isinstance(text, str) and text.startswith('[') and text.endswith(']'):
        text = ' '.join(eval(text))

    # Lowercasing
    text = text.lower()
    # Removing brackets and special characters
    text = re.sub(r'\[.*?\]', '', text)
    # Removing specific special characters: < > \ / , '
    text = re.sub(r'[<>\\/,\'"]', '', text)
    # Removing punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    # Tokenizing
    tokens = word_tokenize(text)
    # Removing stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(tokens)

# Function to calculate readability scores
def calculate_readability_scores(text):
    processed_text = preprocess_text(text)

    fk = flesch_kincaid_grade(processed_text)
    gf = gunning_fog(processed_text)


    return fk, gf


df['flesch_kincaid_score'], df['gunning_fog_score']= zip(*df['text'].apply(calculate_readability_scores))

#We dropped smog index score later as the number of sentences in the dataset rows were less than 30 individually

# Save the updated DataFrame to a new CSV file
from google.colab import files
readabilityScore_df.to_csv('readabilityScore_df.csv', index=True)

# Download the CSV file
files.download('readabilityScore_df.csv')


print("Readability scores calculated and saved to 'updated_dataset_with_scores.csv'")

df.head(10)

