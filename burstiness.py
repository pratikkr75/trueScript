# -*- coding: utf-8 -*-
"""Burstiness.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dmVUaBfuhLbo8ljkaV3TRIxb9cYextQ1
"""

from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
path = "/content/drive/MyDrive/text_dataset.csv"
df = pd.read_csv(path)

columns_to_preserve = ['text', 'label']
mask = df['text'].str.contains('[a-zA-Z]', regex=True)
df_filtered = df[mask][columns_to_preserve]
df = df_filtered

df = df[['text', 'label']]
df.head()

df['text'] = df['text'].apply(lambda x: ' '.join(eval(x)))

def preprocess_text(text):
    # Lowercasing
    text = text.lower()
    # Removing brackets and special characters
    text = re.sub(r'\[.*?\]', '', text)
    # Removing specific special characters: < > \ / , '
    text = re.sub(r'[<>\\/,\'"]', '', text)
    # Removing punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    # Tokenizing
    tokens = word_tokenize(text)
    # Removing stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(tokens)

df['text'] = df['text'].apply(preprocess_text)

#for tokenize using nltk
import numpy as np
import nltk
from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist
from nltk.corpus import stopwords
import string
import re
nltk.download('punkt')
nltk.download('stopwords')



def compute_burstiness(text):
    words = text
    #words = text.split()
    word_counts={}
    for word in words:
      if word in word_counts:
        word_counts[word]+=1
      else:
        word_counts[word]=1
    frequencies = np.array(list(word_counts.values()))
    mean_freq = np.mean(frequencies)
    variance = np.var(frequencies)
    std_dev = variance**0.5;
    # burstiness_score = (std_dev - mean_freq) / (std_dev + mean_freq)
    burstiness_score = (variance - mean_freq) / (variance + mean_freq)
    # burstiness_score = variance/mean_freq**2
    return burstiness_score

df['burstiness1'] = df['text'].apply(compute_burstiness)
df.head();

df.head()

#for tokenize using  nltk(plots) && formula 1
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))

label_0 = df[df['label'] == 0]
plt.scatter(label_0.index, label_0['burstiness1'], color='red', label='Label 0')
label_1 = df[df['label'] == 1]
plt.scatter(label_1.index, label_1['burstiness1'], color='blue', label='Label 1')

plt.title('Burstiness Scores by Label')
plt.xlabel('Index')
plt.ylabel('Burstiness')
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))

# Creating box plot
df.boxplot(column='burstiness1', by='label', grid=False)

plt.title('Burstiness Scores Distribution by Label')
plt.xlabel('Label')
plt.ylabel('Burstiness')
plt.show()

avg_burstiness1 = df.groupby('label')['burstiness1'].mean()
median_burstiness1 = df.groupby('label')['burstiness1'].median()
std_dev_burstiness1 = df.groupby('label')['burstiness1'].std()

print(avg_burstiness1)
print(median_burstiness1)
print(std_dev_burstiness1)

#if we tokenize using nltk and formula 2
import numpy as np
import nltk
from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist
from nltk.corpus import stopwords
import string
nltk.download('punkt')
nltk.download('stopwords')


def compute_burstiness(text):
    words = text
    word_counts={}
    for word in words:
      if word in word_counts:
        word_counts[word]+=1
      else:
        word_counts[word]=1
    frequencies = np.array(list(word_counts.values()))
    mean_freq = np.mean(frequencies)
    variance = np.var(frequencies)
    burstiness_score = variance/mean_freq**2
    return burstiness_score

df['burstiness2'] = df['text'].apply(compute_burstiness)

#if we tokenize using formula2()
# PLOTS

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))

label_0 = df[df['label'] == 0]
plt.scatter(label_0.index, label_0['burstiness2'], color='red', label='Label 0')
label_1 = df[df['label'] == 1]
plt.scatter(label_1.index, label_1['burstiness2'], color='blue', label='Label 1')

plt.title('Burstiness Scores by Label')
plt.xlabel('Index')
plt.ylabel('Burstiness')
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))

# Creating box plot
df.boxplot(column='burstiness2', by='label', grid=False)

plt.title('Burstiness Scores Distribution by Label')
plt.xlabel('Label')
plt.ylabel('Burstiness')
plt.show()

avg_burstiness2 = df.groupby('label')['burstiness2'].mean()
median_burstiness2 = df.groupby('label')['burstiness2'].median()
std_dev_burstiness2 = df.groupby('label')['burstiness2'].std()

print(avg_burstiness2)
print(median_burstiness2)
print(std_dev_burstiness2)

from google.colab import files
df.to_csv('text_og.csv', index=True)

# Download the CSV file
files.download('text_og.csv')

print(df)

path = "/content/drive/MyDrive/perplexity.csv"
pf = pd.read_csv(path)

df['mean_perplexity'] = pf['mean_perplexity']